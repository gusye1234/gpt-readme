import os
import openai
import argparse
from rich.markdown import Markdown
from .constants import ext2language, console, scan_exts
from . import constants
from .utils import construct_prompt, get_cache_config, set_cache_config
from .dir_summary import dir_summary
from .file_summary import file_summary
from .prompts import FINAL_PROMPT, SYSTEM_PROMPT


def parse_args():
    parser = argparse.ArgumentParser(
        description='GPT-readme: Use ChatGPT to write README, based on your code.'
    )
    parser.add_argument(
        "--path",
        type=str,
        default="./",
        help='The local path for your code repo/file',
    )
    parser.add_argument(
        "--exts",
        type=str,
        default="py,cpp",
        help='Select your code extension name, split by comma, e.g. py,cpp',
    )
    parser.add_argument(
        "--language",
        type=str,
        default="english",
        help='Select your readme language',
    )
    parser.add_argument(
        "--demand",
        type=str,
        default="No false summary is allowed",
        help='Additional requires for the gpt-readme',
    )
    parser.add_argument(
        "--out",
        type=str,
        default="./readme.md",
        help='Select where your readme file should be saved',
    )
    parser.add_argument(
        "--cache",
        type=bool,
        default=True,
        help='Cache the summary of the code, to speed up the generation of next time. It will leave a .gpt_readme.json file under the path',
    )
    parser.add_argument(
        "--model",
        type=str,
        default="gpt-3.5-turbo",
        help='Select the GPT model to use for generating the README. Default is "gpt-3.5-turbo".',
    )
    return parser.parse_args()


def prompt_summary(**kwargs):
    final_prompt = FINAL_PROMPT.format(**kwargs)
    final_system = SYSTEM_PROMPT.format(
        **kwargs, human_language=constants.envs['human_language']
    )
    response = openai.ChatCompletion.create(
        model=kwargs['model'],
        messages=construct_prompt(final_system, final_prompt),
        temperature=0,
    )
    return response['choices'][0]['message']['content']


def main():
    args = parse_args()
    local_path = os.path.relpath(args.path)

    constants.envs['human_language'] = args.language
    if args.cache:
        constants.envs['cache'] = get_cache_config(local_path)
    for ext in args.exts.split(","):
        ext = ext.strip()
        if not ext:
            continue
        if ext in ext2language:
            scan_exts.append(ext)
        else:
            console.log(
                f"Extension [{ext}] is not supported yet, please use one of [{','.join(ext2language.keys())}]"
            )
    if os.path.isfile(local_path):
        summaries = file_summary(local_path, args.model)
    else:
        summaries = dir_summary(local_path, args.model)
    if args.cache:
        set_cache_config(local_path, constants.envs["cache"])
    readme = prompt_summary(
        language=summaries['language'],
        module_summaries=summaries['content'],
        path=local_path,
        user_demand=args.demand,
        model=args.model,
    )
    console.rule("ReadMe")
    console.print(Markdown(readme))
    with open(args.out, 'w') as f:
        f.write(
            f"""
<div align="center">
    <a href="https://github.com/gusye1234/gpt-readme">
      <img src="https://img.shields.io/badge/written_by-GPT-green">
    </a>
    <a href="https://github.com/gusye1234/gpt-readme">
      <img src="https://img.shields.io/badge/could_be-Wrong-red">
    </a>
    <a href="https://pypi.org/project/gpt_readme/">
      <img src="https://img.shields.io/pypi/v/gpt_readme.svg">
    </a>
</div>

*This readme generated by command: `gpt_readme --path="{args.path}" --demand="{args.demand}" --language="{args.language} --model="{args.model}"`*

"""
        )
        f.write(readme)
    console.rule("Done")
